# GraphRAGä»0åˆ°1

## ç›®å½•
- [indexå·¥ä½œæµ](#indexå·¥ä½œæµ) 
    - [ä¸€ã€åˆ›å»ºåŸºæœ¬æ–‡æœ¬å•å…ƒ](#ä¸€åˆ›å»ºåŸºæœ¬æ–‡æœ¬å•å…ƒ)
    - [äºŒã€æå–å›¾è°±](#äºŒæå–å›¾è°±)
    - [ä¸‰ã€å®Œå–„å›¾è°±](#ä¸‰å®Œå–„å›¾è°±)
    - [å››ã€æå–åå˜é‡](#å››æå–åå˜é‡)
    - [äº”ã€åˆ›å»ºç¤¾åŒº](#äº”åˆ›å»ºç¤¾åŒº)
    - [å…­ã€åˆ›å»ºæœ€ç»ˆæ–‡æœ¬å•å…ƒ](#å…­åˆ›å»ºæœ€ç»ˆæ–‡æœ¬å•å…ƒ)
    - [ä¸ƒã€ç”Ÿæˆç¤¾åŒºæŠ¥å‘Š](#ä¸ƒç”Ÿæˆç¤¾åŒºæŠ¥å‘Š)
    - [å…«ã€å‘é‡åŒ–](#å…«å‘é‡åŒ–)


## indexå·¥ä½œæµ
æ ‡å‡†æ¨¡å¼æŒ‰ç…§å¦‚ä¸‹å·¥ä½œæµæ‰§è¡Œï¼š
```python
case IndexingMethod.Standard:
    return [
        "create_base_text_units",
        "create_final_documents",
        "extract_graph",
        "finalize_graph",
        *(["extract_covariates"] if config.extract_claims.enabled else []),
        "create_communities",
        "create_final_text_units",
        "create_community_reports",
        "generate_text_embeddings",
        *(update_workflows if is_update_run else []),
    ]
```

## ä¸€ã€åˆ›å»ºåŸºæœ¬æ–‡æœ¬å•å…ƒ
æ ¸å¿ƒæºç ï¼š
```python
documents = await load_table_from_storage("documents", context.storage)
chunks = config.chunks

output = create_base_text_units(
    documents,
    ...
)
#  åˆ†å—
aggregated = aggregated.apply(lambda row: chunker(row), axis=1)
```
#### ducuments.parquet
documents: pd.DataFrame
columns:
- id: uuid
- text: txtæ–‡ä»¶æ–‡æœ¬å†…å®¹
- title: txtæ–‡ä»¶å
- creation_date:åˆ›å»ºæ—¶é—´

#### text_units.parquet
output:  pd.DataFrame
columns:
- text: æ–‡æœ¬å—æ–‡æœ¬
- document_ids: æ–‡æœ¬å—å¯¹åº”çš„txtæ–‡ä»¶id
- n_tokens: æ–‡æœ¬å—çš„tokenæ•°é‡

åˆ†å—ç­–ç•¥ï¼š
sizeå†³å®šå•ä¸ªæ–‡æœ¬å—é•¿åº¦, overlapå†³å®šå—ä¹‹é—´é‡å çš„é•¿åº¦
```text
# settings.yamlä¸­é…ç½®
chunks:
- size: 1200
- overlap: 100
- group_by_columns: [id]
```




## äºŒã€åˆ›å»ºæœ€ç»ˆæ–‡æ¡£

å°†åˆ†æ•£çš„æ–‡æœ¬å•å…ƒ(text units)æŒ‰ç…§å®ƒä»¬æ‰€å±çš„æ–‡æ¡£(document)è¿›è¡Œé‡ç»„ï¼Œ ä¿¡æ¯é‡æ–°æ‹¼æ¥åˆ°text_units.parquetä¸­
æ ¸å¿ƒæºç ï¼š
```python
output = create_final_documents(documents, text_units)
```
è¾“å…¥ï¼š
- documents: ducuments.parquet
- text_units: text_units.parquet

è¾“å‡ºï¼š documents.parquet
- columns:
    - id
    - human_readable_id
    - text
    - n_tokens
    - document_ids
    - entity_ids
    - relationship_ids
    - covariate_ids

## ä¸‰ã€æå–å›¾è°±

### 1. æå–å®ä½“å’Œå…³ç³»
æ ¸å¿ƒå‡½æ•°ä¸ºï¼š
```python
async def _process_document(
        self, text: str, prompt_variables: dict[str, str]
    ) -> str:
        response = await self._model.achat(
            self._extraction_prompt.format(**{
                **prompt_variables,
                self._input_text_key: text,
            }),
        )
        results = response.output.content or ""

        if self._max_gleanings > 0:
            for i in range(self._max_gleanings):
                response = await self._model.achat(
                    CONTINUE_PROMPT,
                    name=f"extract-continuation-{i}",
                    history=response.history,
                )
                results += response.output.content or ""

                # if this is the final glean, don't bother updating the continuation flag
                if i >= self._max_gleanings - 1:
                    break

                response = await self._model.achat(
                    LOOP_PROMPT,
                    name=f"extract-loopcheck-{i}",
                    history=response.history,
                )
                if response.output.content != "Y":
                    break

        return results
```
è¾“å…¥ä¸º: text_units.parquet
- pd.DataFrame
    - columnsåŒ…æ‹¬: 
        - id: æ–‡æœ¬å•å…ƒçš„id
        - text: **æ–‡æœ¬å•å…ƒçš„æ–‡æœ¬**
        - document_ids: æ–‡æœ¬å•å…ƒæ‰€å±æ–‡æ¡£çš„id
        - n_tokens: æ–‡æœ¬å•å…ƒçš„tokenæ•°

è¾“å‡ºä¸º: `entities.parquet` å’Œ `relationship.parquet`
- entities.parquet
    - columnsåŒ…æ‹¬: 
        - title: å®ä½“åç§°
        - type: å®ä½“ç±»å‹
        - text_units_id:: å¼•ç”¨çš„æ–‡æœ¬å•å…ƒid
        - frequency: å®ä½“å‡ºç°çš„æ¬¡æ•°
        - description: æè¿° `[list]`

- relationship.parquet
    - columnsåŒ…æ‹¬:
        - source: å…³ç³»çš„èµ·å§‹å®ä½“
        - target: å…³ç³»çš„ç›®æ ‡å®ä½“
        - text_units_id: å¼•ç”¨çš„æ–‡æœ¬å•å…ƒid
        - weight: å…³ç³»æƒé‡
        - description: æè¿° `[list]`
        


å…·ä½“å·¥ä½œåŸç†å¦‚ä¸‹ï¼š

1. é¦–å…ˆï¼Œç³»ç»Ÿä½¿ç”¨è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPTï¼‰å¯¹æ–‡æ¡£è¿›è¡Œä¸€æ¬¡åˆå§‹æå–ï¼Œè·å–å®ä½“å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚

2. å¦‚æœ`max_gleanings`è®¾ç½®ä¸ºå¤§äº0çš„å€¼ï¼Œç³»ç»Ÿä¼šç»§ç»­è¿›è¡Œé¢å¤–çš„æå–è½®æ¬¡ï¼Œæœ€å¤šè¿›è¡Œ`max_gleanings`æ¬¡é¢å¤–æå–ï¼š
   - ç³»ç»Ÿä¼šå‘è¯­è¨€æ¨¡å‹å‘é€`CONTINUE_PROMPT`æç¤ºï¼Œè¦æ±‚å®ƒç»§ç»­æå–å¯èƒ½é—æ¼çš„å®ä½“å’Œå…³ç³»
   - ç„¶åç³»ç»Ÿä¼šå‘è¯­è¨€æ¨¡å‹å‘é€`LOOP_PROMPT`æç¤ºï¼Œè¯¢é—®æ˜¯å¦è¿˜æœ‰æ›´å¤šå®ä½“å’Œå…³ç³»éœ€è¦æå–
   - å¦‚æœè¯­è¨€æ¨¡å‹å›ç­”"Y"ï¼Œåˆ™ç»§ç»­ä¸‹ä¸€è½®æå–ï¼›å¦‚æœå›ç­”"N"æˆ–å·²è¾¾åˆ°`max_gleanings`æ¬¡æ•°ï¼Œåˆ™åœæ­¢æå–

3. é»˜è®¤æƒ…å†µä¸‹ï¼Œ`max_gleanings`çš„å€¼ä¸º1ï¼Œè¡¨ç¤ºé™¤äº†åˆæ¬¡æå–å¤–ï¼Œæœ€å¤šå†è¿›è¡Œä¸€æ¬¡é¢å¤–æå–ã€‚

### 2. æè¿°æ€»ç»“

æ ¸å¿ƒæºç 
```python
async def _summarize_descriptions(
        self, id: str | tuple[str, str], descriptions: list[str]
    ) -> str:
    """Summarize descriptions into a single description."""
    sorted_id = sorted(id) if isinstance(id, list) else id

    # Safety check, should always be a list
    if not isinstance(descriptions, list):
        descriptions = [descriptions]

    # Sort description lists
    if len(descriptions) > 1:
        descriptions = sorted(descriptions)

    # Iterate over descriptions, adding all until the max input tokens is reached
    usable_tokens = self._max_input_tokens - num_tokens_from_string(
        self._summarization_prompt
    )
    descriptions_collected = []
    result = ""

    for i, description in enumerate(descriptions):
        usable_tokens -= num_tokens_from_string(description)
        descriptions_collected.append(description)

        # If buffer is full, or all descriptions have been added, summarize
        if (usable_tokens < 0 and len(descriptions_collected) > 1) or (
            i == len(descriptions) - 1
        ):
            # Calculate result (final or partial)
            result = await self._summarize_descriptions_with_llm(
                sorted_id, descriptions_collected
            )

            # If we go for another loop, reset values to new
            if i != len(descriptions) - 1:
                descriptions_collected = [result]
                usable_tokens = (
                    self._max_input_tokens
                    - num_tokens_from_string(self._summarization_prompt)
                    - num_tokens_from_string(result)
                )

    return result
```
ç®—æ³•æµç¨‹ï¼š
```text
[desc1, desc2, desc3, desc4, desc5] 
    â†“ (tokené™åˆ¶ï¼Œå¤„ç†å‰3ä¸ª)
summary1 = summarize([desc1, desc2, desc3])
    â†“ (ç»§ç»­å¤„ç†)
[summary1, desc4, desc5]
    â†“ (æœ€ç»ˆæ€»ç»“)
final_result = summarize([summary1, desc4, desc5])
```

è¾“å…¥ï¼š`entities.parquet` å’Œ `relationship.parquet`
è¾“å‡ºä¸ºï¼š`entity_summaries`å’Œ `relationship_summaries`ï¼Œåˆå¹¶åˆ°è¾“å…¥ä¸­ã€‚å³å°†åŸæ¥çš„`description`åˆ—è¡¨æ›¿æ¢ä¸º`summarized_description`

**config.snapshots.raw_graph**å†³å®š`raw_entities`å’Œ`raw_relationships`æ˜¯å¦ä¿å­˜


## å››ã€ç”Ÿæˆå›¾è°±
`finalize_graph`å…·ä½“è®¡ç®—äº†ä»¥ä¸‹åˆ—ä»¥åŠè®¡ç®—æ–¹æ³•ï¼š

### ğŸ“Š å®ä½“è¡¨ (Entities) æ–°å¢/è®¡ç®—çš„åˆ—

#### 1. **degree (åº¦æ•°)**
è¯¥å®ä½“ä½œä¸ºsourceæˆ–targetå‡ºç°åœ¨å¤šå°‘æ¡å…³ç³»ä¸­
```python
# è®¡ç®—æ–¹æ³•
graph = create_graph(relationships, edge_attr=["weight"])
degrees = compute_degree(graph)  # ä½¿ç”¨NetworkXçš„graph.degree

# å…·ä½“è®¡ç®—
degree = len([edge for edge in graph.edges if node in edge])
# å³ï¼šè¯¥å®ä½“ä½œä¸ºsourceæˆ–targetå‡ºç°åœ¨å¤šå°‘æ¡å…³ç³»ä¸­

# ç¼ºå¤±å€¼å¤„ç†
final_entities["degree"] = final_entities["degree"].fillna(0).astype(int)
```

#### 2. **x, y (åæ ‡ä½ç½®)**
```python
# è®¡ç®—æ–¹æ³•
layout = layout_graph(graph, callbacks, layout_enabled, embeddings=graph_embeddings)

# ä¸¤ç§è®¡ç®—æ–¹å¼ï¼š
# æ–¹å¼1ï¼šé›¶å¸ƒå±€ (layout_enabled=False)
x, y = 0, 0  # æ‰€æœ‰èŠ‚ç‚¹éƒ½åœ¨åŸç‚¹

# æ–¹å¼2ï¼šUMAPå¸ƒå±€ (layout_enabled=True)
# åŸºäºå›¾ç»“æ„å’Œå¯é€‰çš„åµŒå…¥å‘é‡è®¡ç®—2Dåæ ‡
positions = umap.fit_transform(node_features)
x, y = positions[node_index]
```
**å‚æ•°config.umap.enabledå†³å®šæ˜¯å¦ä½¿ç”¨UMAPå¸ƒå±€**

### ğŸ“ˆ å…³ç³»è¡¨ (Relationships) æ–°å¢/è®¡ç®—çš„åˆ—

#### 1. **combined_degree (ç»„åˆåº¦æ•°)**
```python
# è®¡ç®—æ–¹æ³•
def compute_edge_combined_degree(edge_df, node_degree_df, ...):
    # æ­¥éª¤1ï¼šè·å–æºèŠ‚ç‚¹åº¦æ•°
    source_degrees = edge_df.merge(
        node_degree_df.rename(columns={"title": "source", "degree": "source_degree"}),
        on="source", how="left"
    )
    
    # æ­¥éª¤2ï¼šè·å–ç›®æ ‡èŠ‚ç‚¹åº¦æ•°  
    target_degrees = source_degrees.merge(
        node_degree_df.rename(columns={"title": "target", "degree": "target_degree"}),
        on="target", how="left"
    )
    
    # æ­¥éª¤3ï¼šè®¡ç®—ç»„åˆåº¦æ•°
    combined_degree = target_degrees["source_degree"] + target_degrees["target_degree"]
    
    return combined_degree

# å…·ä½“å«ä¹‰ï¼šå…³ç³»ä¸¤ç«¯èŠ‚ç‚¹çš„åº¦æ•°ä¹‹å’Œ
# ä¾‹ï¼šå¼ ä¸‰(åº¦æ•°5) â†â†’ æå››(åº¦æ•°3) â†’ combined_degree = 8
```

### ğŸ“‹ æœ€ç»ˆè¾“å‡ºåˆ—

#### å®ä½“è¡¨æœ€ç»ˆåˆ— (ENTITIES_FINAL_COLUMNS)ï¼š
```python
[
    "id",                    # UUIDæ ‡è¯†ç¬¦
    "human_readable_id",     # å¯è¯»æ•´æ•°ID  
    "title",                 # å®ä½“åç§° (åŸæœ‰)
    "type",                  # å®ä½“ç±»å‹ (åŸæœ‰)
    "description",           # å®ä½“æè¿° (åŸæœ‰)
    "text_unit_ids",         # æ–‡æœ¬å•å…ƒID (åŸæœ‰)
    "degree",                # åº¦æ•° (æ–°è®¡ç®—)
    "x",                     # Xåæ ‡ (æ–°è®¡ç®—)
    "y"                      # Yåæ ‡ (æ–°è®¡ç®—)
]
```

#### å…³ç³»è¡¨æœ€ç»ˆåˆ— (RELATIONSHIPS_FINAL_COLUMNS)ï¼š
```python
[
    "id",                    # UUIDæ ‡è¯†ç¬¦
    "human_readable_id",     # å¯è¯»æ•´æ•°ID
    "source",                # æºå®ä½“ (åŸæœ‰)
    "target",                # ç›®æ ‡å®ä½“ (åŸæœ‰)  
    "description",           # å…³ç³»æè¿° (åŸæœ‰)
    "text_unit_ids",         # æ–‡æœ¬å•å…ƒID (åŸæœ‰)
    "weight",                # å…³ç³»æƒé‡ (åŸæœ‰)
    "combined_degree"        # ç»„åˆåº¦æ•° (æ–°è®¡ç®—)
]
```

### ğŸ’¡ è®¡ç®—æ„ä¹‰æ€»ç»“

| åˆ—å | è®¡ç®—æ–¹æ³• | ä¸šåŠ¡æ„ä¹‰ |
|------|----------|----------|
| **degree** | ç»Ÿè®¡è¿æ¥è¾¹æ•° | å®ä½“é‡è¦æ€§æŒ‡æ ‡ |
| **x, y** | å›¾å¸ƒå±€ç®—æ³• | å¯è§†åŒ–åæ ‡ |
| **combined_degree** | ä¸¤ç«¯åº¦æ•°ç›¸åŠ  | å…³ç³»é‡è¦æ€§æŒ‡æ ‡ |

è¿™äº›è®¡ç®—ä¸ºåŸå§‹çš„å®ä½“-å…³ç³»æ•°æ®å¢åŠ äº†**æ‹“æ‰‘ç‰¹å¾**ã€**ç©ºé—´ä¿¡æ¯**å’Œ**å”¯ä¸€æ ‡è¯†**ï¼Œä½¿æ•°æ®å…·å¤‡äº†ç”¨äºæ£€ç´¢ã€æ’åºã€å¯è§†åŒ–å’Œåˆ†æçš„å®Œæ•´å±æ€§ã€‚


## äº”ã€åˆ›å»ºç¤¾åŒº

**å°†çŸ¥è¯†å›¾è°±ä¸­çš„å®ä½“å’Œå…³ç³»æ•°æ®è½¬æ¢ä¸ºåˆ†å±‚çš„ç¤¾åŒºç»“æ„**ï¼Œé€šè¿‡å›¾èšç±»ç®—æ³•è‡ªåŠ¨å‘ç°å®ä½“ä¹‹é—´çš„ç¾¤ä½“å…³ç³»ï¼Œå¹¶æ„å»ºå…·æœ‰å±‚æ¬¡ç»“æ„çš„ç¤¾åŒºæ•°æ®ã€‚

### è¾“å…¥å‚æ•°

```python
def create_communities(
    entities: pd.DataFrame,        # å®ä½“æ•°æ®è¡¨
    relationships: pd.DataFrame,   # å…³ç³»æ•°æ®è¡¨  
    max_cluster_size: int,        # æœ€å¤§èšç±»å¤§å°
    use_lcc: bool,               # æ˜¯å¦ä½¿ç”¨æœ€å¤§è¿é€šåˆ†é‡
    seed: int | None = None,     # éšæœºç§å­ï¼ˆå¯é€‰ï¼‰
) -> pd.DataFrame:
```

#### è¾“å…¥æ•°æ®ç»“æ„ï¼š

**entities DataFrame** - å®ä½“è¡¨ï¼š
- `id`: å®ä½“å”¯ä¸€æ ‡è¯†ç¬¦
- `title`: å®ä½“åç§°/æ ‡é¢˜
- å…¶ä»–å®ä½“å±æ€§...

**relationships DataFrame** - å…³ç³»è¡¨ï¼š
- `id`: å…³ç³»å”¯ä¸€æ ‡è¯†ç¬¦
- `source`: æºå®ä½“åç§°
- `target`: ç›®æ ‡å®ä½“åç§°
- `weight`: å…³ç³»æƒé‡
- `text_unit_ids`: ç›¸å…³æ–‡æœ¬å•å…ƒIDåˆ—è¡¨

### è¾“å‡º

å‡½æ•°è¿”å›ä¸€ä¸ªåŒ…å«ç¤¾åŒºä¿¡æ¯çš„`pd.DataFrame`ï¼Œå…·ä½“åˆ—ç»“æ„ç”±`COMMUNITIES_FINAL_COLUMNS`å®šä¹‰ï¼š

```python
COMMUNITIES_FINAL_COLUMNS = [
    "id",                    # ç¤¾åŒºå”¯ä¸€UUID
    "human_readable_id",     # äººç±»å¯è¯»çš„çŸ­IDï¼ˆç­‰äºcommunityï¼‰
    "community",             # Leidenç®—æ³•ç”Ÿæˆçš„ç¤¾åŒºID
    "level",                 # ç¤¾åŒºåœ¨å±‚æ¬¡ç»“æ„ä¸­çš„æ·±åº¦
    "parent",                # çˆ¶ç¤¾åŒºID
    "children",              # å­ç¤¾åŒºIDåˆ—è¡¨
    "title",                 # ç¤¾åŒºå‹å¥½åç§°
    "entity_ids",            # ç¤¾åŒºæˆå‘˜å®ä½“IDåˆ—è¡¨
    "relationship_ids",      # ç¤¾åŒºå†…éƒ¨å…³ç³»IDåˆ—è¡¨
    "text_unit_ids",         # ç¤¾åŒºç›¸å…³æ–‡æœ¬å•å…ƒIDåˆ—è¡¨
    "period",                # æ•°æ®æ‘„å–æ—¥æœŸï¼ˆISO8601æ ¼å¼ï¼‰
    "size",                  # ç¤¾åŒºå¤§å°ï¼ˆå®ä½“æ•°é‡ï¼‰
]
```

#### è¾“å‡ºæ•°æ®ç¤ºä¾‹ï¼š

```python
{
    "id": "uuid-12345",
    "human_readable_id": 1,
    "community": 1,
    "level": 0,
    "parent": -1,
    "children": [],
    "title": "Community 1",
    "entity_ids": ["E1", "E2", "E3"],
    "relationship_ids": ["R1", "R2", "R3"],
    "text_unit_ids": ["T1", "T2", "T3"],
    "period": "2024-01-15",
    "size": 3
}
```

#### æ ¸å¿ƒåŠŸèƒ½ç‰¹ç‚¹

1. **åˆ†å±‚ç¤¾åŒºæ£€æµ‹**: ä½¿ç”¨Leidenç®—æ³•ç”Ÿæˆå¤šå±‚æ¬¡çš„ç¤¾åŒºç»“æ„
2. **å…³ç³»çº¦æŸ**: åªä¿ç•™æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹éƒ½åœ¨åŒä¸€ç¤¾åŒºå†…çš„å…³ç³»
3. **å®Œæ•´æ€§ä¿è¯**: æ¯ä¸ªç¤¾åŒºåŒ…å«å®Œæ•´çš„å®ä½“ã€å…³ç³»å’Œæ–‡æœ¬å•å…ƒä¿¡æ¯
4. **å±‚æ¬¡ç»“æ„ç»´æŠ¤**: ä¿æŒçˆ¶å­å…³ç³»ï¼Œæ”¯æŒæ ‘å½¢ç»“æ„éå†
5. **å¢é‡æ›´æ–°æ”¯æŒ**: åŒ…å«æ—¶é—´æˆ³å’Œå¤§å°ä¿¡æ¯ï¼Œä¾¿äºåç»­å¢é‡æ›´æ–°

## å…­ã€åˆ›å»ºæœ€ç»ˆæ–‡æœ¬å•å…ƒ
åˆ›å»ºæœ€ç»ˆæ–‡æœ¬å•å…ƒè¡¨ï¼Œå°†åŸå§‹æ–‡æœ¬å•å…ƒè¡¨ä¸å®ä½“å’Œå…³ç³»è¡¨è¿›è¡Œå…³è”ï¼Œç”ŸæˆåŒ…å«å®ä½“å’Œå…³ç³»ä¿¡æ¯çš„æ–‡æœ¬å•å…ƒè¡¨ã€‚


`create_final_text_units` å‡½æ•°çš„è¾“å…¥è¾“å‡ºç»“æ„ï¼š
### è¾“å…¥ç»“æ„

#### 1. `text_units: pd.DataFrame` (åŸå§‹æ–‡æœ¬å•å…ƒè¡¨)
```python
# è¾“å…¥åˆ—ç»“æ„ï¼ˆè‡³å°‘åŒ…å«ä»¥ä¸‹åˆ—ï¼‰ï¼š
{
    "id": str,           # æ–‡æœ¬å•å…ƒå”¯ä¸€æ ‡è¯†ç¬¦
    "text": str,         # æ–‡æœ¬å†…å®¹
    "document_ids": list[str],  # æ‰€å±æ–‡æ¡£IDåˆ—è¡¨
    "n_tokens": int,     # ä»¤ç‰Œæ•°é‡
    # å¯èƒ½è¿˜æœ‰å…¶ä»–åˆ—ï¼Œä½†å‡½æ•°åªä½¿ç”¨ä¸Šè¿°4åˆ—
}
```

#### 2. `final_entities: pd.DataFrame` (æœ€ç»ˆå®ä½“è¡¨)
```python
# è¾“å…¥åˆ—ç»“æ„ï¼š
{
    "id": str,                    # å®ä½“ID
    "text_unit_ids": list[str],   # è¯¥å®ä½“å‡ºç°çš„æ–‡æœ¬å•å…ƒIDåˆ—è¡¨
    # å…¶ä»–å®ä½“ç›¸å…³åˆ—...
}
```

#### 3. `final_relationships: pd.DataFrame` (æœ€ç»ˆå…³ç³»è¡¨)
```python
# è¾“å…¥åˆ—ç»“æ„ï¼š
{
    "id": str,                    # å…³ç³»ID
    "text_unit_ids": list[str],   # è¯¥å…³ç³»å‡ºç°çš„æ–‡æœ¬å•å…ƒIDåˆ—è¡¨
    # å…¶ä»–å…³ç³»ç›¸å…³åˆ—...
}
```

### è¾“å‡ºç»“æ„

#### `pd.DataFrame` (æœ€ç»ˆæ–‡æœ¬å•å…ƒè¡¨)
```python
# è¾“å‡ºåˆ—ç»“æ„ï¼ˆä¸¥æ ¼æŒ‰ç…§ TEXT_UNITS_FINAL_COLUMNS å®šä¹‰ï¼‰ï¼š
{
    "id": str,                      # æ–‡æœ¬å•å…ƒID
    "human_readable_id": int,       # äººç±»å¯è¯»IDï¼ˆä»1å¼€å§‹çš„åºå·ï¼‰
    "text": str,                    # æ–‡æœ¬å†…å®¹
    "n_tokens": int,                # ä»¤ç‰Œæ•°é‡
    "document_ids": list[str],      # æ‰€å±æ–‡æ¡£IDåˆ—è¡¨
    "entity_ids": list[str],        # å…³è”çš„å®ä½“IDåˆ—è¡¨
    "relationship_ids": list[str],  # å…³è”çš„å…³ç³»IDåˆ—è¡¨
    "covariate_ids": list[str],     # å…³è”çš„åå˜é‡IDåˆ—è¡¨
}
```

## ä¸ƒã€ç”Ÿæˆç¤¾åŒºæŠ¥å‘Š

### æ ¸å¿ƒå‡½æ•° `create_community_reports`

#### 1. å®ä½“å±•å¹³:å°†ç¤¾åŒºä¸­æ‰€æœ‰å®ä½“å±•å¹³ï¼Œæ¯ä¸ªå®ä½“å•ç‹¬ä¸€è¡Œ
```python
nodes = explode_communities(communities, entities)
```

**explode_communities å‡½æ•°è¯¦è§£ï¼š**
```python
def explode_communities(communities: pd.DataFrame, entities: pd.DataFrame) -> pd.DataFrame:
    # å°†communitiesä¸­çš„entity_idsåˆ—è¡¨å±•å¼€ï¼Œæ¯ä¸ªentity_idä¸€è¡Œ
    community_join = communities.explode("entity_ids").loc[:, ["community", "level", "entity_ids"]]
    
    # å°†å®ä½“è¡¨ä¸ç¤¾åŒºè¡¨æŒ‰entity_idå…³è”
    nodes = entities.merge(community_join, left_on="id", right_on="entity_ids", how="left")
    
    # è¿‡æ»¤æ‰ä¸å±äºä»»ä½•ç¤¾åŒºçš„èŠ‚ç‚¹ (community != -1)
    return nodes.loc[nodes.loc[:, COMMUNITY_ID] != -1]
```


#### 2. æ„å»ºä¸Šä¸‹æ–‡ï¼ˆé‡è¦ï¼ï¼ï¼ï¼‰
##### ğŸ” **å±‚çº§ä¸Šä¸‹æ–‡ vs æœ¬åœ°ä¸Šä¸‹æ–‡è¯¦è§£**

###### ğŸ“ **æœ¬åœ°ä¸Šä¸‹æ–‡ (Local Context)**

**å®šä¹‰**ï¼šæœ¬åœ°ä¸Šä¸‹æ–‡æ˜¯æŒ‡ç›´æ¥ä»å›¾æ•°æ®ä¸­æå–çš„åŸå§‹ä¿¡æ¯ï¼ŒåŒ…å«ç¤¾åŒºå†…çš„å®ä½“ã€å…³ç³»å’Œå£°æ˜çš„è¯¦ç»†ä¿¡æ¯ã€‚

**æ„å»ºè¿‡ç¨‹**ï¼š
```python
def build_local_context(nodes, edges, claims, callbacks, max_context_tokens=16_000):
    """ä¸ºæŠ¥å‘Šç”Ÿæˆå‡†å¤‡ç¤¾åŒºæ•°æ®"""
    # 1. è·å–æ‰€æœ‰å±‚çº§
    levels = get_levels(nodes, schemas.COMMUNITY_LEVEL)
    
    # 2. ä¸ºæ¯ä¸ªå±‚çº§æ„å»ºæœ¬åœ°ä¸Šä¸‹æ–‡
    for level in levels:
        communities_at_level_df = _prepare_reports_at_level(
            nodes, edges, claims, level, max_context_tokens
        )
```

**åŒ…å«å†…å®¹**ï¼š
- **å®ä½“ä¿¡æ¯**ï¼šèŠ‚ç‚¹çš„æ ‡é¢˜ã€æè¿°ã€åº¦æ•°ç­‰
- **å…³ç³»ä¿¡æ¯**ï¼šè¾¹çš„æºã€ç›®æ ‡ã€æè¿°ã€æƒé‡ç­‰  
- **å£°æ˜ä¿¡æ¯**ï¼šä¸å®ä½“ç›¸å…³çš„å£°æ˜å’Œè¯æ®
- **åŸå§‹å›¾ç»“æ„**ï¼šç›´æ¥ä»çŸ¥è¯†å›¾è°±ä¸­æå–çš„ç»“æ„åŒ–æ•°æ®

**ç‰¹ç‚¹**ï¼š
- âœ… ä¿¡æ¯æœ€è¯¦ç»†ã€æœ€å®Œæ•´
- âŒ å¯èƒ½è¶…å‡ºtokené™åˆ¶
- ğŸ¯ é€‚ç”¨äºå°è§„æ¨¡ç¤¾åŒº

###### ğŸ“ **å±‚çº§ä¸Šä¸‹æ–‡ (Level Context)**

**å®šä¹‰**ï¼šå±‚çº§ä¸Šä¸‹æ–‡æ˜¯ä¸€ç§æ™ºèƒ½çš„ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥ï¼Œå½“æœ¬åœ°ä¸Šä¸‹æ–‡è¶…å‡ºtokené™åˆ¶æ—¶ï¼Œç”¨å­ç¤¾åŒºçš„æŠ¥å‘Šæ¥æ›¿ä»£è¯¦ç»†çš„æœ¬åœ°ä¿¡æ¯ã€‚

**æ„å»ºè¿‡ç¨‹**ï¼š
```python
def build_level_context(report_df, community_hierarchy_df, local_context_df, level, max_context_tokens):
    """ä¸ºç»™å®šå±‚çº§çš„æ¯ä¸ªç¤¾åŒºå‡†å¤‡ä¸Šä¸‹æ–‡
    
    å¯¹äºæ¯ä¸ªç¤¾åŒºï¼š
    - æ£€æŸ¥æœ¬åœ°ä¸Šä¸‹æ–‡æ˜¯å¦åœ¨é™åˆ¶å†…ï¼Œå¦‚æœæ˜¯åˆ™ä½¿ç”¨æœ¬åœ°ä¸Šä¸‹æ–‡
    - å¦‚æœæœ¬åœ°ä¸Šä¸‹æ–‡è¶…å‡ºé™åˆ¶ï¼Œåˆ™è¿­ä»£åœ°ç”¨å­ç¤¾åŒºæŠ¥å‘Šæ›¿æ¢æœ¬åœ°ä¸Šä¸‹æ–‡ï¼Œä»æœ€å¤§çš„å­ç¤¾åŒºå¼€å§‹
    """
```

**æ™ºèƒ½æ›¿æ¢ç­–ç•¥**ï¼š

1. **æœ‰æ•ˆä¸Šä¸‹æ–‡æ£€æŸ¥**ï¼š
```python
# è¿‡æ»¤æœ‰æ•ˆå’Œæ— æ•ˆçš„ä¸Šä¸‹æ–‡
valid_context_df = level_context_df[~level_context_df[schemas.CONTEXT_EXCEED_FLAG]]
invalid_context_df = level_context_df[level_context_df[schemas.CONTEXT_EXCEED_FLAG]]
```

2. **å­ç¤¾åŒºæŠ¥å‘Šæ›¿æ¢**ï¼š
```python
# å¯¹äºæ¯ä¸ªæ— æ•ˆä¸Šä¸‹æ–‡ï¼Œå°è¯•ç”¨å­ç¤¾åŒºæŠ¥å‘Šæ›¿æ¢
sub_context_df = _get_subcontext_df(level + 1, report_df, local_context_df)
community_df = _get_community_df(level, invalid_context_df, sub_context_df, 
                                community_hierarchy_df, max_context_tokens)
```

3. **æ··åˆä¸Šä¸‹æ–‡æ„å»º**ï¼š
```python
# æ„å»ºæ··åˆä¸Šä¸‹æ–‡ï¼Œä¼˜å…ˆä½¿ç”¨æŠ¥å‘Šï¼Œå¿…è¦æ—¶ä¿ç•™æœ¬åœ°ä¸Šä¸‹æ–‡
community_df[schemas.CONTEXT_STRING] = community_df[schemas.ALL_CONTEXT].apply(
    lambda x: build_mixed_context(x, max_context_tokens)
)
```

##### ğŸ”„ **ä¸¤è€…çš„å…³ç³»å’Œè½¬æ¢**

###### **å±‚çº§åŒ–å¤„ç†æµç¨‹**ï¼š

```
ğŸ“Š æœ¬åœ°ä¸Šä¸‹æ–‡ (è¯¦ç»†åŸå§‹æ•°æ®)
    â†“ (å¦‚æœè¶…å‡ºtokené™åˆ¶)
ğŸ”„ å±‚çº§ä¸Šä¸‹æ–‡ (æ™ºèƒ½æ›¿æ¢ç­–ç•¥)
    â†“ (ç”¨å­ç¤¾åŒºæŠ¥å‘Šæ›¿æ¢)
ğŸ“ æœ€ç»ˆä¸Šä¸‹æ–‡ (é€‚åˆLLMå¤„ç†)
```

###### **å…·ä½“æ›¿æ¢é€»è¾‘**ï¼š

1. **æ£€æŸ¥é˜¶æ®µ**ï¼š
   - è®¡ç®—æœ¬åœ°ä¸Šä¸‹æ–‡çš„tokenæ•°é‡
   - æ ‡è®°è¶…å‡ºé™åˆ¶çš„ç¤¾åŒº (`CONTEXT_EXCEED_FLAG`)

2. **æ›¿æ¢é˜¶æ®µ**ï¼š
   - è·å–å­ç¤¾åŒºçš„å·²ç”ŸæˆæŠ¥å‘Š
   - æŒ‰å¤§å°æ’åºï¼Œä¼˜å…ˆæ›¿æ¢æœ€å¤§çš„å­ç¤¾åŒº
   - ä¿æŒåœ¨tokené™åˆ¶å†…

3. **æ··åˆé˜¶æ®µ**ï¼š
   - ç»“åˆå­ç¤¾åŒºæŠ¥å‘Šå’Œå‰©ä½™çš„æœ¬åœ°ä¸Šä¸‹æ–‡
   - ç¡®ä¿æœ€ç»ˆä¸Šä¸‹æ–‡ç¬¦åˆè¦æ±‚



#### 3. ç¤¾åŒºæ€»ç»“
åŸºäºä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆç¤¾åŒºæ€»ç»“

##### 3.1 åˆ†å±‚å¤„ç†æœºåˆ¶
```python
levels = get_levels(nodes, schemas.COMMUNITY_LEVEL)  # è·å–å±‚çº§ [2, 1, 0] ï¼ˆ2 ä¸ºæœ€ä½å±‚ï¼Œæ•°å­—è¶Šå¤§å±‚çº§è¶Šä½ï¼‰
for level in levels:  # ä»ä½å±‚çº§åˆ°é«˜å±‚çº§å¤„ç†
    # é«˜å±‚çº§å¯ä»¥åˆ©ç”¨ä½å±‚çº§å·²ç”Ÿæˆçš„æŠ¥å‘Š
```

##### 3.2 ä¸Šä¸‹æ–‡é•¿åº¦ç®¡ç†
```python
# åœ¨build_level_contextä¸­
if context_size > max_context_tokens:
    # ä½¿ç”¨å­ç¤¾åŒºæŠ¥å‘Šæ›¿ä»£è¯¦ç»†çš„æœ¬åœ°ä¸Šä¸‹æ–‡
    use_sub_community_reports()
else:
    # ä½¿ç”¨å®Œæ•´çš„æœ¬åœ°ä¸Šä¸‹æ–‡
    use_local_context()
```

## å…«ã€å‘é‡åŒ–
 `generate_text_embeddings` å‡½æ•°ä¸»è¦è´Ÿè´£ä¸ºçŸ¥è¯†å›¾è°±ä¸­çš„å„ç§æ–‡æœ¬æ•°æ®ç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆembeddingsï¼‰ã€‚

### å…·ä½“å·¥ä½œï¼š

1. **å¤„ç†å¤šç§æ•°æ®ç±»å‹çš„åµŒå…¥**ï¼š
   - æ–‡æ¡£æ–‡æœ¬åµŒå…¥ (`document_text_embedding`)
   - å…³ç³»æè¿°åµŒå…¥ (`relationship_description_embedding`) 
   - æ–‡æœ¬å•å…ƒåµŒå…¥ (`text_unit_text_embedding`)
   - å®ä½“æ ‡é¢˜åµŒå…¥ (`entity_title_embedding`)
   - å®ä½“æè¿°åµŒå…¥ (`entity_description_embedding`)
   - ç¤¾åŒºæ ‡é¢˜åµŒå…¥ (`community_title_embedding`)
   - ç¤¾åŒºæ‘˜è¦åµŒå…¥ (`community_summary_embedding`)
   - ç¤¾åŒºå®Œæ•´å†…å®¹åµŒå…¥ (`community_full_content_embedding`)

2. **æ•°æ®é¢„å¤„ç†**ï¼š
   - ä»è¾“å…¥çš„ DataFrame ä¸­æå–ç›¸å…³çš„ ID å’Œæ–‡æœ¬åˆ—
   - å¯¹äºå®ä½“æè¿°åµŒå…¥ï¼Œä¼šå°†æ ‡é¢˜å’Œæè¿°åˆå¹¶ä¸º "title:description" æ ¼å¼

3. **æ‰¹é‡ç”ŸæˆåµŒå…¥**ï¼š
   - æ ¹æ®é…ç½®ä¸­æŒ‡å®šçš„ `embedded_fields` æ¥å†³å®šéœ€è¦ç”Ÿæˆå“ªäº›ç±»å‹çš„åµŒå…¥
   - è°ƒç”¨ `_run_and_snapshot_embeddings` å‡½æ•°æ¥å®é™…æ‰§è¡ŒåµŒå…¥ç”Ÿæˆ

è¿™ä¸ªå‡½æ•°æ˜¯ GraphRAG æµæ°´çº¿ä¸­çš„å…³é”®æ­¥éª¤ï¼Œå®ƒå°†ç»“æ„åŒ–çš„çŸ¥è¯†å›¾è°±æ•°æ®è½¬æ¢ä¸ºå¯ä»¥è¿›è¡Œè¯­ä¹‰æœç´¢å’Œç›¸ä¼¼æ€§åŒ¹é…çš„å‘é‡è¡¨ç¤ºï¼Œä¸ºåç»­çš„æ£€ç´¢å’Œç”Ÿæˆä»»åŠ¡å¥ å®šåŸºç¡€ã€‚





